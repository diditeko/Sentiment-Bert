{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NCLckcr5ZVvC",
    "outputId": "9fe2fef0-55ed-4bab-fb03-52e09de7b1e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting psycopg2-binary\n",
      "  Downloading psycopg2_binary-2.9.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.11/dist-packages (2.0.40)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy) (3.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy) (4.13.2)\n",
      "Downloading psycopg2_binary-2.9.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m135.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m79.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: psycopg2-binary\n",
      "Successfully installed psycopg2-binary-2.9.10\n"
     ]
    }
   ],
   "source": [
    "!pip install psycopg2-binary sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pIPUlsIe6odJ"
   },
   "outputs": [],
   "source": [
    "!pip install sentencepiece -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SiEz3KpV4m01",
    "outputId": "69debddf-3651-4080-a347-2257f7cadbc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
      "Collecting datasets\n",
      "  Downloading datasets-3.5.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Downloading datasets-3.5.1-py3-none-any.whl (491 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.4/491.4 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2025.3.2\n",
      "    Uninstalling fsspec-2025.3.2:\n",
      "      Successfully uninstalled fsspec-2025.3.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed datasets-3.5.1 dill-0.3.8 fsspec-2025.3.0 multiprocess-0.70.16 xxhash-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bmvVF9HxnMkr",
    "outputId": "ac6e9a4c-fb4e-4f8a-8dcf-83d1bb1f3b98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting supabase\n",
      "  Downloading supabase-2.15.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting gotrue<3.0.0,>=2.11.0 (from supabase)\n",
      "  Downloading gotrue-2.12.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: httpx<0.29,>=0.26 in /usr/local/lib/python3.11/dist-packages (from supabase) (0.28.1)\n",
      "Collecting postgrest<1.1,>0.19 (from supabase)\n",
      "  Downloading postgrest-1.0.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting realtime<2.5.0,>=2.4.0 (from supabase)\n",
      "  Downloading realtime-2.4.3-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting storage3<0.12,>=0.10 (from supabase)\n",
      "  Downloading storage3-0.11.3-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting supafunc<0.10,>=0.9 (from supabase)\n",
      "  Downloading supafunc-0.9.4-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.10 in /usr/local/lib/python3.11/dist-packages (from gotrue<3.0.0,>=2.11.0->supabase) (2.11.3)\n",
      "Requirement already satisfied: pyjwt<3.0.0,>=2.10.1 in /usr/local/lib/python3.11/dist-packages (from gotrue<3.0.0,>=2.11.0->supabase) (2.10.1)\n",
      "Collecting pytest-mock<4.0.0,>=3.14.0 (from gotrue<3.0.0,>=2.11.0->supabase)\n",
      "  Downloading pytest_mock-3.14.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.26->supabase) (4.9.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.26->supabase) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.26->supabase) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.26->supabase) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<0.29,>=0.26->supabase) (0.16.0)\n",
      "Collecting deprecation<3.0.0,>=2.1.0 (from postgrest<1.1,>0.19->supabase)\n",
      "  Downloading deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.11.18 (from realtime<2.5.0,>=2.4.0->supabase)\n",
      "  Downloading aiohttp-3.11.18-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from realtime<2.5.0,>=2.4.0->supabase) (2.9.0.post0)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.13.2 in /usr/local/lib/python3.11/dist-packages (from realtime<2.5.0,>=2.4.0->supabase) (4.13.2)\n",
      "Collecting websockets<15,>=11 (from realtime<2.5.0,>=2.4.0->supabase)\n",
      "  Downloading websockets-14.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting strenum<0.5.0,>=0.4.15 (from supafunc<0.10,>=0.9->supabase)\n",
      "  Downloading StrEnum-0.4.15-py3-none-any.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.18->realtime<2.5.0,>=2.4.0->supabase) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.18->realtime<2.5.0,>=2.4.0->supabase) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.18->realtime<2.5.0,>=2.4.0->supabase) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.18->realtime<2.5.0,>=2.4.0->supabase) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.18->realtime<2.5.0,>=2.4.0->supabase) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.18->realtime<2.5.0,>=2.4.0->supabase) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.18->realtime<2.5.0,>=2.4.0->supabase) (1.20.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from deprecation<3.0.0,>=2.1.0->postgrest<1.1,>0.19->supabase) (24.2)\n",
      "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.11/dist-packages (from httpx[http2]<0.29,>=0.26->gotrue<3.0.0,>=2.11.0->supabase) (4.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10->gotrue<3.0.0,>=2.11.0->supabase) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10->gotrue<3.0.0,>=2.11.0->supabase) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10->gotrue<3.0.0,>=2.11.0->supabase) (0.4.0)\n",
      "Requirement already satisfied: pytest>=6.2.5 in /usr/local/lib/python3.11/dist-packages (from pytest-mock<4.0.0,>=3.14.0->gotrue<3.0.0,>=2.11.0->supabase) (8.3.5)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3.0.0,>=2.8.1->realtime<2.5.0,>=2.4.0->supabase) (1.17.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<0.29,>=0.26->supabase) (1.3.1)\n",
      "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]<0.29,>=0.26->gotrue<3.0.0,>=2.11.0->supabase) (6.1.0)\n",
      "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]<0.29,>=0.26->gotrue<3.0.0,>=2.11.0->supabase) (4.1.0)\n",
      "Requirement already satisfied: iniconfig in /usr/local/lib/python3.11/dist-packages (from pytest>=6.2.5->pytest-mock<4.0.0,>=3.14.0->gotrue<3.0.0,>=2.11.0->supabase) (2.1.0)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.11/dist-packages (from pytest>=6.2.5->pytest-mock<4.0.0,>=3.14.0->gotrue<3.0.0,>=2.11.0->supabase) (1.5.0)\n",
      "Downloading supabase-2.15.1-py3-none-any.whl (17 kB)\n",
      "Downloading gotrue-2.12.0-py3-none-any.whl (43 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading postgrest-1.0.1-py3-none-any.whl (22 kB)\n",
      "Downloading realtime-2.4.3-py3-none-any.whl (22 kB)\n",
      "Downloading storage3-0.11.3-py3-none-any.whl (17 kB)\n",
      "Downloading supafunc-0.9.4-py3-none-any.whl (7.8 kB)\n",
      "Downloading aiohttp-3.11.18-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
      "Downloading pytest_mock-3.14.0-py3-none-any.whl (9.9 kB)\n",
      "Downloading StrEnum-0.4.15-py3-none-any.whl (8.9 kB)\n",
      "Downloading websockets-14.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (169 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.9/169.9 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: strenum, websockets, deprecation, pytest-mock, aiohttp, realtime, supafunc, storage3, postgrest, gotrue, supabase\n",
      "  Attempting uninstall: websockets\n",
      "    Found existing installation: websockets 15.0.1\n",
      "    Uninstalling websockets-15.0.1:\n",
      "      Successfully uninstalled websockets-15.0.1\n",
      "  Attempting uninstall: aiohttp\n",
      "    Found existing installation: aiohttp 3.11.15\n",
      "    Uninstalling aiohttp-3.11.15:\n",
      "      Successfully uninstalled aiohttp-3.11.15\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed aiohttp-3.11.18 deprecation-2.1.0 gotrue-2.12.0 postgrest-1.0.1 pytest-mock-3.14.0 realtime-2.4.3 storage3-0.11.3 strenum-0.4.15 supabase-2.15.1 supafunc-0.9.4 websockets-14.2\n"
     ]
    }
   ],
   "source": [
    "!pip install supabase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gk97ralE_uos"
   },
   "source": [
    "#Load data from Superbase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VcW46QjMA8tU"
   },
   "outputs": [],
   "source": [
    "from supabase import create_client, Client\n",
    "\n",
    "# Replace these with your actual values\n",
    "url = \"https://xgoupvtfpgijyrdlvifp.supabase.co\"\n",
    "key = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6Inhnb3VwdnRmcGdpanlyZGx2aWZwIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NDQ5NTU0MTUsImV4cCI6MjA2MDUzMTQxNX0.7_KfQnu6nCLej66rQwWNVnOpFAafLM_IAv7vi_bsl_Q\"\n",
    "\n",
    "supabase: Client = create_client(url, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "30mVdIRmbOZf",
    "outputId": "13160619-1550-43f9-ad15-75024ffb141d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id                                              tweet  sentiment  \\\n",
      "0          1  @GanjaranApp Semoga setelah ini keamanan negar...          1   \n",
      "1          2  @_ikhwanyan Demi keamanan negara Australia pan...          0   \n",
      "2          5  @liputan6dotcom Petugas bea cukainya terlalu i...          0   \n",
      "3          6  Sementara itu, merespons dinamika lingkungan s...          1   \n",
      "4          7  @Midjan_La_2 KKB-OPM harus ditindak tegas tanp...          0   \n",
      "...      ...                                                ...        ...   \n",
      "12935  16995  Tak pandang bulu! @KejaksaanRI memanggil Mente...          1   \n",
      "12936  16996  Sukses terus pak! Saya dukung agar menjadi Pre...          1   \n",
      "12937  16997         æ´å©äº¤éã¯å£²æ¥ãã¹ï¼ï¼ï¼ï¼ï¼          0   \n",
      "12938  16998  Presiden Joko Widodo meyakini bahwa pasar trad...          1   \n",
      "12939  16999  @YudaSalim1 Rakyat sudah paham rekam jejak si ...          0   \n",
      "\n",
      "       emotion  \n",
      "0            1  \n",
      "1            5  \n",
      "2            5  \n",
      "3            1  \n",
      "4            5  \n",
      "...        ...  \n",
      "12935        1  \n",
      "12936        1  \n",
      "12937        6  \n",
      "12938        1  \n",
      "12939        5  \n",
      "\n",
      "[12940 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "batch_size = 1000\n",
    "all_data = []\n",
    "offset = 0\n",
    "\n",
    "while True:\n",
    "    response = supabase.table('tweet').select('*').range(offset, offset + batch_size - 1).execute()\n",
    "    data_batch = response.data\n",
    "\n",
    "    if not data_batch:\n",
    "        break  # No more data to fetch\n",
    "\n",
    "    all_data.extend(data_batch)\n",
    "    offset += batch_size\n",
    "\n",
    "# Now create the DataFrame\n",
    "df = pd.DataFrame(all_data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461
    },
    "id": "juOPBlqsnpQo",
    "outputId": "27b7386b-fca4-4e3a-ca92-87e6d90ad45b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df\",\n  \"rows\": 12940,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4848,\n        \"min\": 1,\n        \"max\": 16999,\n        \"num_unique_values\": 12940,\n        \"samples\": [\n          4817,\n          12757,\n          16247\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tweet\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10412,\n        \"samples\": [\n          \"@rmol_id Saya kira densus membunuh teroris....atau keliru yg dibunuh....hukum karma kali...\",\n          \"@CNNIndonesia Mereka itu serius kerja basmi KKB ga sih? Latihan militer mulu basmi teroris ga becus. Muak....\",\n          \"@CNNIndonesia naaahhh para pemerhati teroris saatnya ngetweet dan ngebuzzer ttg ini, ayooo \\u00f0\\u009f\\u0098\\u0080\\u00f0\\u009f\\u0098\\u0080\\u00f0\\u009f\\u0098\\u0080\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0,\n          4,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"emotion\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 11,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          5,\n          6,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-c38841ab-e5ad-47f9-ad3f-2c4016f33d9c\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>@GanjaranApp Semoga setelah ini keamanan negar...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>@_ikhwanyan Demi keamanan negara Australia pan...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>@liputan6dotcom Petugas bea cukainya terlalu i...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>Sementara itu, merespons dinamika lingkungan s...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>@Midjan_La_2 KKB-OPM harus ditindak tegas tanp...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12935</th>\n",
       "      <td>16995</td>\n",
       "      <td>Tak pandang bulu! @KejaksaanRI memanggil Mente...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12936</th>\n",
       "      <td>16996</td>\n",
       "      <td>Sukses terus pak! Saya dukung agar menjadi Pre...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12937</th>\n",
       "      <td>16997</td>\n",
       "      <td>æ´å©äº¤éã¯å£²æ¥ãã¹ï¼ï¼ï¼ï¼ï¼</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12938</th>\n",
       "      <td>16998</td>\n",
       "      <td>Presiden Joko Widodo meyakini bahwa pasar trad...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12939</th>\n",
       "      <td>16999</td>\n",
       "      <td>@YudaSalim1 Rakyat sudah paham rekam jejak si ...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12940 rows × 4 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c38841ab-e5ad-47f9-ad3f-2c4016f33d9c')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-c38841ab-e5ad-47f9-ad3f-2c4016f33d9c button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-c38841ab-e5ad-47f9-ad3f-2c4016f33d9c');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-c11295e8-4b90-4d73-a20b-bde620a2ac10\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c11295e8-4b90-4d73-a20b-bde620a2ac10')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-c11295e8-4b90-4d73-a20b-bde620a2ac10 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "  <div id=\"id_988e55c5-5f54-426e-be68-8796a5e164e7\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_988e55c5-5f54-426e-be68-8796a5e164e7 button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('df');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "          id                                              tweet  sentiment  \\\n",
       "0          1  @GanjaranApp Semoga setelah ini keamanan negar...          1   \n",
       "1          2  @_ikhwanyan Demi keamanan negara Australia pan...          0   \n",
       "2          5  @liputan6dotcom Petugas bea cukainya terlalu i...          0   \n",
       "3          6  Sementara itu, merespons dinamika lingkungan s...          1   \n",
       "4          7  @Midjan_La_2 KKB-OPM harus ditindak tegas tanp...          0   \n",
       "...      ...                                                ...        ...   \n",
       "12935  16995  Tak pandang bulu! @KejaksaanRI memanggil Mente...          1   \n",
       "12936  16996  Sukses terus pak! Saya dukung agar menjadi Pre...          1   \n",
       "12937  16997         æ´å©äº¤éã¯å£²æ¥ãã¹ï¼ï¼ï¼ï¼ï¼          0   \n",
       "12938  16998  Presiden Joko Widodo meyakini bahwa pasar trad...          1   \n",
       "12939  16999  @YudaSalim1 Rakyat sudah paham rekam jejak si ...          0   \n",
       "\n",
       "       emotion  \n",
       "0            1  \n",
       "1            5  \n",
       "2            5  \n",
       "3            1  \n",
       "4            5  \n",
       "...        ...  \n",
       "12935        1  \n",
       "12936        1  \n",
       "12937        6  \n",
       "12938        1  \n",
       "12939        5  \n",
       "\n",
       "[12940 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M9EncIqR_zXp"
   },
   "source": [
    "#Convert to Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4w6-tKz9o3mW",
    "outputId": "85379b82-2fde-4811-df9c-1cdbe3538aac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------+-------+\n",
      "|id |tweet                                                                                                                                                                                                                                                                                   |sentiment|emotion|\n",
      "+---+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------+-------+\n",
      "|1  |@GanjaranApp Semoga setelah ini keamanan negara kita makin bagus dan masyarakat akan semakin meningkat kesejahteraannya..                                                                                                                                                               |1        |1      |\n",
      "|2  |@_ikhwanyan Demi keamanan negara Australia pantas mencopot semua cctv produk china. Beda dengan +62 malah diundang sama manusianya.                                                                                                                                                     |0        |5      |\n",
      "|5  |@liputan6dotcom Petugas bea cukainya terlalu ikut campur urusan keamanan yg tidak dia pahami. Kalo mau menegur samperin bisik2, karena itu keamanan negara yg bisa bikin malu semua. Mau nanya apkh dari dulu gak ada pungli dan korupsi di bea cukai ? Bea cuk                         |0        |5      |\n",
      "|6  |Sementara itu, merespons dinamika lingkungan strategis yang tengah berkembang saat ini para menteri kedua negara sepakat bahwa kemitraan strategis dan kerja sama pertahanan yang telah terjalin oleh kedua negara telah berkontribusi dalam menciptakan stabilitas keamanan di kawasan.|1        |1      |\n",
      "|7  |@Midjan_La_2 KKB-OPM harus ditindak tegas tanpa harus pandang urusan HAM.  Tindakan yang dilakukan kelompok mereka selama ini diluar batas manusiawi.  Semoga TNI dan POLRI bisa bersinergi menuntaskan masalah ini sehingga tidak mengganggu keamanan dan stab                         |0        |5      |\n",
      "+---+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create Spark Session\n",
    "spark = SparkSession.builder.appName(\"Twitter Sentiment Preprocessing\").getOrCreate()\n",
    "\n",
    "# Convert pandas df to spark df\n",
    "spark_df = spark.createDataFrame(df)\n",
    "\n",
    "# Show data\n",
    "spark_df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qf7H8Nw6o9DS",
    "outputId": "ebca967b-a7de-4fbb-98f5-e601cf8618e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+---------+-------+\n",
      "| id|               tweet|sentiment|emotion|\n",
      "+---+--------------------+---------+-------+\n",
      "|  1|@GanjaranApp Semo...|        1|      1|\n",
      "|  2|@_ikhwanyan Demi ...|        0|      5|\n",
      "|  5|@liputan6dotcom P...|        0|      5|\n",
      "|  6|Sementara itu, me...|        1|      1|\n",
      "|  7|@Midjan_La_2 KKB-...|        0|      5|\n",
      "|  8|Sementara itu, me...|        1|      1|\n",
      "|  9|Sementara itu, me...|        1|      1|\n",
      "| 10|Sementara itu, me...|        1|      1|\n",
      "| 11|@detikcom Kenapa ...|        0|      5|\n",
      "| 12|@_ikhwanyan Mungk...|        0|      2|\n",
      "| 13|Dalam dokumen keb...|        1|      1|\n",
      "| 14|Filipina Di Incar...|        1|      1|\n",
      "| 15|@ropspimajainal C...|        0|      5|\n",
      "| 16|@KompasTV Demi st...|        1|      1|\n",
      "| 17|@mazzini_gsp Di l...|        0|      4|\n",
      "| 19|Kepolisian Khusus...|        1|      1|\n",
      "| 24|Kampanye yang ber...|        0|      5|\n",
      "| 26|@YoutubeILC @karn...|        1|      1|\n",
      "| 27|@oreo_koshka27 @w...|        0|      5|\n",
      "| 28|Dari semua gak ad...|        0|      4|\n",
      "+---+--------------------+---------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B7_ozLkorGsG",
    "outputId": "336028df-4da4-4ff7-8af8-08802e26e9cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- tweet: string (nullable = true)\n",
      " |-- sentiment: long (nullable = true)\n",
      " |-- emotion: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KhYHab46rff7",
    "outputId": "d5f05bb4-3e41-4026-b169-be918703a0fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+--------------------+------------------+------------------+\n",
      "|summary|               id|               tweet|         sentiment|           emotion|\n",
      "+-------+-----------------+--------------------+------------------+------------------+\n",
      "|  count|            12940|               12940|             12940|             12940|\n",
      "|   mean|8403.638639876352|                NULL|0.9319165378670788|3.2352395672333847|\n",
      "| stddev|4848.289421255287|                NULL|0.7753754476198541| 2.238950951821062|\n",
      "|    min|                1|#ARIES Asmara: Ba...|                 0|                 0|\n",
      "|    max|            16999|ð« ðGerak Cep...|                 5|                11|\n",
      "+-------+-----------------+--------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1NWn315Fr4vs",
    "outputId": "5e4feb92-ded3-4637-cf83-bceadecb02ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|sentiment|count|\n",
      "+---------+-----+\n",
      "|        0| 4339|\n",
      "|        5|    3|\n",
      "|        1| 5154|\n",
      "|        2| 3443|\n",
      "|        4|    1|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.groupBy(\"sentiment\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XvuTC6zKsMGx",
    "outputId": "12e96614-0f9c-4342-ff1d-bcb1d1fbee2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|emotion|count|\n",
      "+-------+-----+\n",
      "|      0|  902|\n",
      "|      6| 2617|\n",
      "|      5| 3567|\n",
      "|      1| 4683|\n",
      "|      3|  390|\n",
      "|     11|    2|\n",
      "|      2|  332|\n",
      "|      4|  447|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.groupBy(\"emotion\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fipzpEkcsSEy"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "spark_df = spark_df.filter(~col(\"sentiment\").isin(4, 5))\n",
    "spark_df = spark_df.filter(~col(\"emotion\").isin(11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7VdlcUght4w2",
    "outputId": "d509a449-7207-4125-d49a-e0e0879b5007"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|emotion|count|\n",
      "+-------+-----+\n",
      "|      0|  898|\n",
      "|      6| 2617|\n",
      "|      5| 3567|\n",
      "|      1| 4683|\n",
      "|      3|  390|\n",
      "|      2|  332|\n",
      "|      4|  447|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.groupBy(\"emotion\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R2i3guN5uFNK",
    "outputId": "4d528dde-de5b-47f0-da80-68132b0773f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+---------+-------+\n",
      "| id|               tweet|sentiment|emotion|\n",
      "+---+--------------------+---------+-------+\n",
      "|  1|@GanjaranApp Semo...|        1|      1|\n",
      "|  2|@_ikhwanyan Demi ...|        0|      5|\n",
      "|  5|@liputan6dotcom P...|        0|      5|\n",
      "|  6|Sementara itu, me...|        1|      1|\n",
      "|  7|@Midjan_La_2 KKB-...|        0|      5|\n",
      "|  8|Sementara itu, me...|        1|      1|\n",
      "|  9|Sementara itu, me...|        1|      1|\n",
      "| 10|Sementara itu, me...|        1|      1|\n",
      "| 11|@detikcom Kenapa ...|        0|      5|\n",
      "| 12|@_ikhwanyan Mungk...|        0|      2|\n",
      "| 13|Dalam dokumen keb...|        1|      1|\n",
      "| 14|Filipina Di Incar...|        1|      1|\n",
      "| 15|@ropspimajainal C...|        0|      5|\n",
      "| 16|@KompasTV Demi st...|        1|      1|\n",
      "| 17|@mazzini_gsp Di l...|        0|      4|\n",
      "| 19|Kepolisian Khusus...|        1|      1|\n",
      "| 24|Kampanye yang ber...|        0|      5|\n",
      "| 26|@YoutubeILC @karn...|        1|      1|\n",
      "| 27|@oreo_koshka27 @w...|        0|      5|\n",
      "| 28|Dari semua gak ad...|        0|      4|\n",
      "+---+--------------------+---------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NQMl59zT_8fh"
   },
   "source": [
    "#Preprocessing Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "hTWW0LSFJmdS",
    "outputId": "276d8055-e44d-4a04-ec2c-9a221e357e5a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
      "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping\n",
      "[nltk_data]    |       taggers/averaged_perceptron_tagger_eng.zip.\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping\n",
      "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_rus to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping\n",
      "[nltk_data]    |       taggers/averaged_perceptron_tagger_rus.zip.\n",
      "[nltk_data]    | Downloading package basque_grammars to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
      "[nltk_data]    | Downloading package bcp47 to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package biocreative_ppi to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
      "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
      "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
      "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
      "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
      "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
      "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
      "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
      "[nltk_data]    | Downloading package comparative_sentences to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
      "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
      "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
      "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
      "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
      "[nltk_data]    | Downloading package english_wordnet to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/english_wordnet.zip.\n",
      "[nltk_data]    | Downloading package europarl_raw to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
      "[nltk_data]    | Downloading package extended_omw to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
      "[nltk_data]    | Downloading package framenet_v15 to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
      "[nltk_data]    | Downloading package framenet_v17 to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
      "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
      "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
      "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
      "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
      "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
      "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
      "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
      "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package large_grammars to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
      "[nltk_data]    | Downloading package lin_thesaurus to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
      "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
      "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker_tab to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker_tab.zip.\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger_tab to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping\n",
      "[nltk_data]    |       taggers/maxent_treebank_pos_tagger_tab.zip.\n",
      "[nltk_data]    | Downloading package moses_sample to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
      "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
      "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
      "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/names.zip.\n",
      "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
      "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
      "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package opinion_lexicon to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
      "[nltk_data]    | Downloading package pe08 to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/pe08.zip.\n",
      "[nltk_data]    | Downloading package perluniprops to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
      "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
      "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
      "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
      "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
      "[nltk_data]    | Downloading package problem_reports to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
      "[nltk_data]    | Downloading package product_reviews_1 to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
      "[nltk_data]    | Downloading package product_reviews_2 to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
      "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
      "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
      "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data]    | Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping tokenizers/punkt_tab.zip.\n",
      "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
      "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
      "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
      "[nltk_data]    | Downloading package sample_grammars to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
      "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
      "[nltk_data]    | Downloading package sentence_polarity to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
      "[nltk_data]    | Downloading package sentiwordnet to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
      "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
      "[nltk_data]    | Downloading package sinica_treebank to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
      "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    | Downloading package spanish_grammars to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
      "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
      "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data]    | Downloading package subjectivity to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
      "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
      "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
      "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
      "[nltk_data]    | Downloading package tagsets_json to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping help/tagsets_json.zip.\n",
      "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
      "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
      "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
      "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
      "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
      "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    | Downloading package vader_lexicon to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
      "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
      "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
      "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
      "[nltk_data]    | Downloading package word2vec_sample to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
      "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package wordnet2022 to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/wordnet2022.zip.\n",
      "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
      "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/words.zip.\n",
      "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection all\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "import re\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Make sure you have NLTK punkt downloaded\n",
    "import nltk\n",
    "nltk.download('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0J6VTR4rP-Wp"
   },
   "outputs": [],
   "source": [
    "# Set partition first\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", \"4\")\n",
    "spark_df = spark_df.repartition(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LfwuYT0ASCQX",
    "outputId": "2733a0c7-4121-4119-8608-eac061fa8256"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12934"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#chace data\n",
    "spark_df.cache()\n",
    "spark_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZipcNPxbS7x3"
   },
   "outputs": [],
   "source": [
    "def preprocess_text_spark(text):\n",
    "    if text is None:\n",
    "        return []\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove tab, newline, backslash\n",
    "    text = text.replace('\\\\t', ' ').replace('\\\\n', ' ').replace('\\\\u', '').replace('\\\\', '')\n",
    "    # Remove non-ASCII characters\n",
    "    text = text.encode('ascii', 'replace').decode('ascii')\n",
    "    # Remove mention, link, hashtag\n",
    "    text = ' '.join(re.sub(r\"([@#][A-Za-z0-9]+)|(\\w+:\\/\\/\\S+)\", \" \", text).split())\n",
    "    # Remove incomplete URL\n",
    "    text = text.replace(\"http://\", \" \").replace(\"https://\", \" \")\n",
    "    # Remove numbers\n",
    "    text = re.sub(r\"\\d+\", \"\", text)\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Remove leading/trailing whitespace\n",
    "    text = text.strip()\n",
    "    # Remove multiple whitespace\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    # Remove single characters\n",
    "    text = re.sub(r\"\\b[a-zA-Z]\\b\", '', text)\n",
    "    # Tokenize using NLTK\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yfpSGT8-TBxO"
   },
   "outputs": [],
   "source": [
    "# Register as UDF\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "\n",
    "preprocess_text_udf = F.udf(preprocess_text_spark, ArrayType(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "id": "iWt2SELnTHBI",
    "outputId": "57462ada-4694-425b-b432-c10e3a604764"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
       "      pre.function-repr-contents {\n",
       "        overflow-x: auto;\n",
       "        padding: 8px 12px;\n",
       "        max-height: 500px;\n",
       "      }\n",
       "\n",
       "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
       "        cursor: pointer;\n",
       "        max-height: 100px;\n",
       "      }\n",
       "    </style>\n",
       "    <pre style=\"white-space: initial; background:\n",
       "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
       "         border-bottom: 1px solid var(--colab-border-color);\"><b>preprocess_text_spark</b><br/>def preprocess_text_spark(text)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/content/&lt;ipython-input-20-281bbddcd60c&gt;</a>&lt;no docstring&gt;</pre></div>"
      ],
      "text/plain": [
       "<function __main__.preprocess_text_spark(text)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_text_udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "46l5XB5lTKYw"
   },
   "outputs": [],
   "source": [
    "# Apply to create a new column 'tweet_preprocess'\n",
    "spark_df = spark_df.withColumn(\"tweet_preprocess\", preprocess_text_udf(F.col(\"tweet\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K8UOG9LiTj_w",
    "outputId": "f5de325f-023e-4fe5-ee8c-2f9d221b024d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+---------+-------+--------------------+\n",
      "|  id|               tweet|sentiment|emotion|    tweet_preprocess|\n",
      "+----+--------------------+---------+-------+--------------------+\n",
      "|2507|@tni_ad Bravo Kod...|        1|      1|[ad, bravo, kodim...|\n",
      "|1983|@innamisme1 Ada b...|        0|      4|[ada, baiknya, la...|\n",
      "|1035|Nah ini Panglima ...|        1|      0|[nah, ini, pangli...|\n",
      "|5837|@agenkripiktahu H...|        2|      6|[hai, kak, mohon,...|\n",
      "| 588|Tegas! Panglima T...|        1|      1|[tegas, panglima,...|\n",
      "|4826|Kepada seluruh pi...|        1|      1|[kepada, seluruh,...|\n",
      "|1289|Tahukah #SanakMin...|        1|      1|[tahukah, kegiata...|\n",
      "|7539|Jadi remaja harus...|        1|      1|[jadi, remaja, ha...|\n",
      "|3940|Menjaga jarak dar...|        1|      4|[menjaga, jarak, ...|\n",
      "|5107|Hidup ini indah j...|        2|      6|[hidup, ini, inda...|\n",
      "|5017|@robiutsaniee @yo...|        1|      6|[aresee, ya, ndak...|\n",
      "|5045|Ya Allah. Aku tau...|        1|      6|[ya, allah, aku, ...|\n",
      "|3919|Orang yang mengin...|        1|      0|[orang, yang, men...|\n",
      "| 518|Momen Haru Kopka ...|        1|      1|[momen, haru, kop...|\n",
      "|1803|Gak ada duanya de...|        1|      1|[gak, ada, duanya...|\n",
      "| 960|Panglima TNI : Ju...|        1|      1|[panglima, tni, j...|\n",
      "|3356|@virza1 @Dony_YNW...|        1|      4|[ynwa, anakkolong...|\n",
      "|5121|@YuliantiZulkif1 ...|        2|      6|[ku, morafia, net...|\n",
      "|6940|PERS POLSEK KOTA ...|        2|      1|[pers, polsek, ko...|\n",
      "|3890|Salah satu hasil ...|        1|      1|[salah, satu, has...|\n",
      "+----+--------------------+---------+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CAoh_zurTl0r",
    "outputId": "17bb5266-990d-4240-d062-539add64094c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sastrawi\n",
      "  Downloading Sastrawi-1.0.1-py2.py3-none-any.whl.metadata (909 bytes)\n",
      "Downloading Sastrawi-1.0.1-py2.py3-none-any.whl (209 kB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/209.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m204.8/209.7 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.7/209.7 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sastrawi\n",
      "Successfully installed sastrawi-1.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install sastrawi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eGhq7YtrYzdF"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Prepare stopwords set\n",
    "indonesian_stopwords = set(stopwords.words('indonesian'))\n",
    "\n",
    "# Broadcast to Spark cluster\n",
    "broadcast_stopwords = spark.sparkContext.broadcast(indonesian_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R4jO1UXAZt6I"
   },
   "outputs": [],
   "source": [
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GEB92CDpZxxO"
   },
   "outputs": [],
   "source": [
    "def stopword_stemmer_spark(tokens):\n",
    "    if tokens is None:\n",
    "        return []\n",
    "    # Access stopwords from broadcast\n",
    "    stopwords_set = broadcast_stopwords.value\n",
    "    print(stopwords_set)\n",
    "\n",
    "    # Remove stopwords\n",
    "    tokens_without_stopwords = [word for word in tokens if word not in stopwords_set]\n",
    "    # Stem each token\n",
    "    tokens_stemmed = [stemmer.stem(token) for token in tokens_without_stopwords]\n",
    "\n",
    "    return tokens_stemmed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wfg05JNTZ7mT"
   },
   "outputs": [],
   "source": [
    "stopword_stemmer_udf = F.udf(stopword_stemmer_spark, ArrayType(StringType()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zDr4AJ-6aDTx",
    "outputId": "31e9310b-b116-4eb4-a1f2-2b135bd1a2a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+---------+-------+--------------------+--------------------+\n",
      "|  id|               tweet|sentiment|emotion|    tweet_preprocess|      textdata_stemm|\n",
      "+----+--------------------+---------+-------+--------------------+--------------------+\n",
      "|2507|@tni_ad Bravo Kod...|        1|      1|[ad, bravo, kodim...|[ad, bravo, kodim...|\n",
      "|1983|@innamisme1 Ada b...|        0|      4|[ada, baiknya, la...|[baik, rancang, b...|\n",
      "|1035|Nah ini Panglima ...|        1|      0|[nah, ini, pangli...|[panglima, tni, k...|\n",
      "|5837|@agenkripiktahu H...|        2|      6|[hai, kak, mohon,...|[hai, kak, mohon,...|\n",
      "| 588|Tegas! Panglima T...|        1|      1|[tegas, panglima,...|[panglima, tni, s...|\n",
      "|4826|Kepada seluruh pi...|        1|      1|[kepada, seluruh,...|[jaga, satu, satu...|\n",
      "|1289|Tahukah #SanakMin...|        1|      1|[tahukah, kegiata...|[tahu, giat, bent...|\n",
      "|7539|Jadi remaja harus...|        1|      1|[jadi, remaja, ha...|[remaja, jaga, ja...|\n",
      "|3940|Menjaga jarak dar...|        1|      4|[menjaga, jarak, ...|[jaga, jarak, pol...|\n",
      "|5107|Hidup ini indah j...|        2|      6|[hidup, ini, inda...|[hidup, indah, ja...|\n",
      "|5017|@robiutsaniee @yo...|        1|      6|[aresee, ya, ndak...|[aresee, ya, ndak...|\n",
      "|5045|Ya Allah. Aku tau...|        1|      6|[ya, allah, aku, ...|[ya, allah, tau, ...|\n",
      "|3919|Orang yang mengin...|        1|      0|[orang, yang, men...|[orang, impi, nya...|\n",
      "| 518|Momen Haru Kopka ...|        1|      1|[momen, haru, kop...|[momen, haru, kop...|\n",
      "|1803|Gak ada duanya de...|        1|      1|[gak, ada, duanya...|[gak, dua, dehh, ...|\n",
      "| 960|Panglima TNI : Ju...|        1|      1|[panglima, tni, j...|[panglima, tni, j...|\n",
      "|3356|@virza1 @Dony_YNW...|        1|      4|[ynwa, anakkolong...|[ynwa, anakkolong...|\n",
      "|5121|@YuliantiZulkif1 ...|        2|      6|[ku, morafia, net...|[ku, morafia, net...|\n",
      "|6940|PERS POLSEK KOTA ...|        2|      1|[pers, polsek, ko...|[pers, polsek, ko...|\n",
      "|3890|Salah satu hasil ...|        1|      1|[salah, satu, has...|[salah, hasil, re...|\n",
      "+----+--------------------+---------+-------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Apply the broadcasted stopword + stemmer function\n",
    "spark_df = spark_df.withColumn(\"textdata_stemm\", stopword_stemmer_udf(F.col(\"tweet_preprocess\")))\n",
    "\n",
    "spark_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vjBaeTFjABZY"
   },
   "source": [
    "#convert to pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TbJq-Oe27DCZ"
   },
   "outputs": [],
   "source": [
    "# Select only the columns you want\n",
    "selected_spark_df = spark_df.select('textdata_stemm', 'sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fx7UvweXTn4m"
   },
   "outputs": [],
   "source": [
    "pandas_df = selected_spark_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 144
    },
    "id": "FZVs0cVjbNlz",
    "outputId": "b2c79e1c-04d3-43d6-eece-577172e659f7"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pandas_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-20e5f0939ce2>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpandas_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tes.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pandas_df' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "pandas_df.to_csv(\"tes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "CIusfs8P6yqf",
    "outputId": "e5747984-9b3e-403b-950e-e1e2222d2586"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df\",\n  \"rows\": 12934,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3733,\n        \"min\": 0,\n        \"max\": 12933,\n        \"num_unique_values\": 12934,\n        \"samples\": [\n          7520,\n          5034,\n          12863\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"textdata_stemm\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9128,\n        \"samples\": [\n          \"densus tangkap sangka teroris sumsel lampung\",\n          \"perintah kabupaten dairi tandatangani mou perintah kota medan\",\n          \"perintah panglima tni pilot sus air sandera kkb evakuasi\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          0,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-be41c918-c2db-437b-ad47-fed3f85a086b\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>textdata_stemm</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ad bravo kodim kolaka</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>baik rancang bangun survey lokasi amdal satwa ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>panglima tni kapolri pakai baju adat jateng wk...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>hai kak mohon maaf ketidaknyamanannya jaga pri...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>panglima tni siap operasi pasu batas laut natuna</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12929</th>\n",
       "      <td>12929</td>\n",
       "      <td>teroris bicara</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12930</th>\n",
       "      <td>12930</td>\n",
       "      <td>hic inandirici degilsin provokatorarayada bi t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12931</th>\n",
       "      <td>12931</td>\n",
       "      <td>tolak radikalisme</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12932</th>\n",
       "      <td>12932</td>\n",
       "      <td>waras gp mania bubar gpp rekam jejak ketua gak...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12933</th>\n",
       "      <td>12933</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12934 rows × 3 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-be41c918-c2db-437b-ad47-fed3f85a086b')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-be41c918-c2db-437b-ad47-fed3f85a086b button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-be41c918-c2db-437b-ad47-fed3f85a086b');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-d799db91-1549-43f4-a4bd-03bc559ecca4\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d799db91-1549-43f4-a4bd-03bc559ecca4')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-d799db91-1549-43f4-a4bd-03bc559ecca4 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "  <div id=\"id_60e00045-a632-49f8-9c3d-f0cd60809a3b\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_60e00045-a632-49f8-9c3d-f0cd60809a3b button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('df');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "       Unnamed: 0                                     textdata_stemm  \\\n",
       "0               0                              ad bravo kodim kolaka   \n",
       "1               1  baik rancang bangun survey lokasi amdal satwa ...   \n",
       "2               2  panglima tni kapolri pakai baju adat jateng wk...   \n",
       "3               3  hai kak mohon maaf ketidaknyamanannya jaga pri...   \n",
       "4               4   panglima tni siap operasi pasu batas laut natuna   \n",
       "...           ...                                                ...   \n",
       "12929       12929                                     teroris bicara   \n",
       "12930       12930  hic inandirici degilsin provokatorarayada bi t...   \n",
       "12931       12931                                  tolak radikalisme   \n",
       "12932       12932  waras gp mania bubar gpp rekam jejak ketua gak...   \n",
       "12933       12933                                                NaN   \n",
       "\n",
       "       sentiment  \n",
       "0              1  \n",
       "1              0  \n",
       "2              1  \n",
       "3              2  \n",
       "4              1  \n",
       "...          ...  \n",
       "12929          0  \n",
       "12930          0  \n",
       "12931          1  \n",
       "12932          0  \n",
       "12933          0  \n",
       "\n",
       "[12934 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('tes.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n6h1hPwP-2aL"
   },
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RAOLEt7b_Cr6",
    "outputId": "021ac9e3-6e4d-4585-8a8a-e8123d688b8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 12781 entries, 0 to 12932\n",
      "Data columns (total 3 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   Unnamed: 0      12781 non-null  int64 \n",
      " 1   textdata_stemm  12781 non-null  object\n",
      " 2   sentiment       12781 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 399.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N67GFS0bxZKL"
   },
   "outputs": [],
   "source": [
    "df = df.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 210
    },
    "id": "gfWKLyVz67gu",
    "outputId": "2edcb9c6-7a20-4f56-b4db-a4062ee4ee6d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><br><label><b>dtype:</b> int64</label>"
      ],
      "text/plain": [
       "sentiment\n",
       "1    5070\n",
       "0    4330\n",
       "2    3381\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ia4gAhDYwnMD"
   },
   "source": [
    "#Convert to HuggingFace Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gZ-Yb9SlwzXx"
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "dataset = Dataset.from_pandas(df)\n",
    "dataset = dataset.remove_columns(['__index_level_0__'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CqboSkNMBF3G",
    "outputId": "cca4b20c-c822-4bf1-b162-6db78625c4b1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['textdata_stemm', 'labels'],\n",
       "    num_rows: 12781\n",
       "})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.rename_column(\"sentiment\", \"labels\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OXgEEyRhBUP_"
   },
   "source": [
    "why rename ? because The Hugging Face Trainer expects your target (label) column to be named labels by default."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WZnMLp3TAE3K"
   },
   "source": [
    "#Train Tes Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A_4yYAUVBnBW"
   },
   "outputs": [],
   "source": [
    "# Split: 80% train, 20% test\n",
    "dataset = dataset.train_test_split(test_size=0.2)\n",
    "\n",
    "# Access train and test sets\n",
    "train_dataset = dataset['train']\n",
    "test_dataset = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mRkjIKI5B7Kg",
    "outputId": "b2581eba-8be0-41e6-eb61-cf91aa240d83"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['textdata_stemm', 'labels'],\n",
       "    num_rows: 10224\n",
       "})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kb5P5ZbU3Ybd"
   },
   "source": [
    "#Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272,
     "referenced_widgets": [
      "2c53e6be2edc41e396ee9d091ab70bd2",
      "c707df4ec9cc4b13b85827bb3553bf06",
      "b27ecf584d8e4a82a10c5c10952f1686",
      "3c6bbdb22b0d437aa3eaa0df33e3ff73",
      "9b9444043ec5486192a5c50b7fb95f8f",
      "cdb8693bff2e4f229ccbe00778b674fc",
      "ba50cb1656034649a64c723312d7f8d3",
      "b65e08a887c84013b6fbad524832dd0c",
      "a6a13381e3a848ba86e97f7688c461f8",
      "f590d86a196b42a19281f1c7e17cafae",
      "ee1121b0f985499b9ca8cc1113caa868",
      "0a534125d1a8413fb007c1c91558766c",
      "158854a8f881466a914d155be42ba759",
      "0c31dcfb0bab430ea7ead4ee8f511a47",
      "098e51a298a34b4094bc7c6a08404a9f",
      "0f8c9fddb8fa4c539383568df196c8e3",
      "c49d8a2873bb49c5a6d3b75b9d00c54f",
      "d708b6efd11848f9b7ea5dbddc9558b4",
      "13addd0500864318874ea80051d70d43",
      "6af2592052494a1f925eb39b7e4ccea1",
      "6c0630ae4ff747bfb0011346eedd201d",
      "01778b032c6b4d3e8925850a5eb25c5f",
      "5a70feaed8a84c929fb59c54a051da47",
      "7f94632459754f3f83ff6c3324ccaaf7",
      "b667c5853cca4adb9f20fa0358dc920c",
      "c86daa3abd184dfd9da986104bab2caa",
      "abeae17820f640db9cc07605447d88dc",
      "8307794a37fc4a3f87b1668304ba4d73",
      "d529a3f765bd4b3cb0fd804fdf9d6e02",
      "8e0b73753598469889a82e7ab1047ae2",
      "578dd9e3269745fb8a3f8cde74ac7e05",
      "86079e922fff48a088849b1e7e827eca",
      "887b4ab58ab04d5bbf92d45bb3e09438",
      "cdd5eff32ed045aeab47a07c40ca782e",
      "2f6636e67f2a44a4be14a7aef5466740",
      "f4571fd8ebee495c999a2b020247ea88",
      "df5afcae9a524a329e721a6f139f7cdb",
      "633cf38a7ddb42bdb875747057078055",
      "8a6b1230b3ca4e4085883734652512d0",
      "58ae6cc792764b4eae03ed5a9dbb1ccc",
      "a92ea7a2504b4013bf4c25df83cb0e12",
      "b5f7b7623f4b4429b95b18190c52065d",
      "d7b61cc386964895b5207ef7a8b623bb",
      "a9ead99c6c8a4a9a89b3ab573f13cbb0"
     ]
    },
    "id": "5_oC1KQH3bGq",
    "outputId": "920a7c4d-63ee-4ac6-b0c2-9bbb0913029e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c53e6be2edc41e396ee9d091ab70bd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a534125d1a8413fb007c1c91558766c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/229k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a70feaed8a84c929fb59c54a051da47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdd5eff32ed045aeab47a07c40ca782e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import BertTokenizer, AutoModel\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"indobenchmark/indobert-base-p1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MRqio3Iv8AfH",
    "outputId": "3b36ca15-c68b-44e6-eef7-b37b3e41424b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gak jaga aman ketentraman negara\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[4][\"textdata_stemm\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "aef75210f276432ca1530fbcfd818117",
      "e43a8673201f40f3ac82157874e8ab4e",
      "eb94c77748554129bb6fdf44d38b3820",
      "5bc4fb6f4cbf4a4097edf423b33cde34",
      "6272aae11cf44bcfb2469060dfb1788f",
      "41132add1d2c4a02831d1ab7016984c4",
      "f3b82230849a4455a3b2558931a9412a",
      "3a081d0c03264454a07ffa0875820156",
      "d48226be5886418dba8c4eaae809729f",
      "55fb1230f4264f868f39d43374446634",
      "2b02930a55fc48d6af02a810f5e98a51",
      "8003d86217354ec49fad0c4a13f83101",
      "024ed03747b84873a2bd508bcf6e731a",
      "d86aa03a09c84795883d34ba9898ed8a",
      "5ee4bc7d41374d129b2cef64ec7f921c",
      "0356b8dc1d1a4fa9bb1312e853b9887f",
      "6b21a3fcfbcd40ae9924f4239f213576",
      "9cf89c6a7a354d32afa2e15efcda87a8",
      "4b2482442ac3488ebf85d7b0bf5de9e7",
      "497acac670c6424fb9a21d24fa1b49c7",
      "5ab2519364a04e5597a4ee1102e16fb5",
      "6c18f6fecbcf4727ab7db43b1763e0f7"
     ]
    },
    "id": "xushQBaH6bOZ",
    "outputId": "c41dc33a-b884-428c-a162-38d8f95fa794"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aef75210f276432ca1530fbcfd818117",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10224 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8003d86217354ec49fad0c4a13f83101",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2557 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_function(batch):\n",
    "    return tokenizer(batch[\"textdata_stemm\"], padding=\"max_length\", max_length=128, truncation=True)\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "alLC4lqWFIFv"
   },
   "outputs": [],
   "source": [
    "# Set format for PyTorch\n",
    "train_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "test_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "Mrh6i5w6KtcT",
    "outputId": "48d6218d-3469-4527-ffd0-f486c53d0867"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': tensor(2),\n",
       " 'input_ids': tensor([   2, 2307, 2688,    3,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0])}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WTBbLS9kHCvN"
   },
   "source": [
    "#Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AlOPl8b7HQiM",
    "outputId": "f9071ff6-5237-42ef-b439-7ed27d6b44f2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"indobenchmark/indobert-base-p1\",\n",
    "    num_labels=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UmUG0UjRKxj6"
   },
   "source": [
    "#Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2_8qqRrsLMQj",
    "outputId": "72e172a7-54cc-485c-bf83-1792d5c6e271"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p-7IzPVsLUQM",
    "outputId": "74ce97b6-9568-4f92-93da-a041dac54212"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.51.3\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XLanCcSSK1OY"
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=50,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4-Qs3EgTMqct",
    "outputId": "1ac00ffc-8d4d-4de6-9e31-d9bfef698112"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.0.2)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.30.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (24.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.11.15)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.1.31)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.20.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
      "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: evaluate\n",
      "Successfully installed evaluate-0.4.3\n"
     ]
    }
   ],
   "source": [
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MVgtcFtGMQvA"
   },
   "outputs": [],
   "source": [
    "import evaluate\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = logits.argmax(axis=-1)\n",
    "    return accuracy.compute(predictions=preds, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mbneCQncNEul",
    "outputId": "3f55409b-90bc-4d05-d02b-2e98a062272d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datasets.arrow_dataset.Dataset'>\n",
      "<class 'datasets.arrow_dataset.Dataset'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_dataset))\n",
    "print(type(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1BnxAqdFM0p4",
    "outputId": "86659a37-7479-4837-95db-1a8e69f13acb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-69-ae01522387ff>:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 460
    },
    "id": "hx-5mvEDNoiI",
    "outputId": "6b097c6f-5f2b-4de6-c800-17c9f574e826"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6390' max='6390' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6390/6390 43:05, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.682700</td>\n",
       "      <td>0.660155</td>\n",
       "      <td>0.703168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.579500</td>\n",
       "      <td>0.661568</td>\n",
       "      <td>0.714118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.440800</td>\n",
       "      <td>0.733025</td>\n",
       "      <td>0.704732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.324700</td>\n",
       "      <td>0.926227</td>\n",
       "      <td>0.710989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.246100</td>\n",
       "      <td>0.964577</td>\n",
       "      <td>0.706296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.235000</td>\n",
       "      <td>1.140978</td>\n",
       "      <td>0.713336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.189800</td>\n",
       "      <td>1.225285</td>\n",
       "      <td>0.709425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.158100</td>\n",
       "      <td>1.341954</td>\n",
       "      <td>0.705905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.121500</td>\n",
       "      <td>1.464624</td>\n",
       "      <td>0.708252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.122100</td>\n",
       "      <td>1.550650</td>\n",
       "      <td>0.709425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=6390, training_loss=0.31520289598682866, metrics={'train_runtime': 2586.3294, 'train_samples_per_second': 39.531, 'train_steps_per_second': 2.471, 'total_flos': 6725178957127680.0, 'train_loss': 0.31520289598682866, 'epoch': 10.0})"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qp5kchOT3JlS"
   },
   "source": [
    "#Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "N2ncP8Vn3MD9",
    "outputId": "7c7ed1fc-85c1-4cfd-db32-bc340ce19622"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='160' max='160' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [160/160 00:18]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6615678071975708, 'eval_accuracy': 0.7141181071568244, 'eval_runtime': 18.4381, 'eval_samples_per_second': 138.68, 'eval_steps_per_second': 8.678, 'epoch': 10.0}\n"
     ]
    }
   ],
   "source": [
    "results = trainer.evaluate()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A1k_dBhy3U-5"
   },
   "source": [
    "#save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3QEFSdjdPqj0",
    "outputId": "18912090-0073-450e-a824-dfffed066076"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('sentiment-bert/tokenizer_config.json',\n",
       " 'sentiment-bert/special_tokens_map.json',\n",
       " 'sentiment-bert/vocab.txt',\n",
       " 'sentiment-bert/added_tokens.json')"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.save_model(\"sentiment-bert\")\n",
    "tokenizer.save_pretrained(\"sentiment-bert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "m5_gKl3Y5G5y",
    "outputId": "4605daa0-81df-4e43-92d3-81392d956dbb"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content/sentiment-bert.zip'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.make_archive(\"sentiment-bert\", 'zip', \"sentiment-bert\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e9VfQAdC4FNV"
   },
   "source": [
    "#Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "71xqAi3U3fwn",
    "outputId": "2b41a943-4463-4bef-e3fb-688af367528d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'Positive', 'score': 0.9583989381790161}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load pipeline\n",
    "sentiment_pipeline = pipeline(\"text-classification\", model=\"sentiment-bert\", tokenizer=\"sentiment-bert\")\n",
    "\n",
    "# Coba prediksi\n",
    "text = \" indonesia maju jaya jaya jaya\"\n",
    "result = sentiment_pipeline(text)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 196
    },
    "id": "vlgWUAAo4KQ2",
    "outputId": "bbbf134e-5010-4793-8067-8a53375f2a7b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negatif       0.78      0.82      0.80       849\n",
      "     Positif       0.71      0.86      0.78      1069\n",
      "      Netral       0.57      0.33      0.42       639\n",
      "\n",
      "    accuracy                           0.71      2557\n",
      "   macro avg       0.69      0.67      0.67      2557\n",
      "weighted avg       0.70      0.71      0.70      2557\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "preds = trainer.predict(test_dataset)\n",
    "y_pred = np.argmax(preds.predictions, axis=1)\n",
    "y_true = preds.label_ids\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=[\"Negatif\", \"Positif\", \"Netral\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6nCKsGaX5eiX"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download(\"sentiment-bert.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17,
     "referenced_widgets": [
      "5a41f67ce33e4b2485d3aa3f244dea35",
      "456d1c0e727e40b18aff01093bcab3ef",
      "61cfd3fdf2b241ed845c29820963e5fc",
      "8243cce02ab24c61a712e1e2d92d11a7",
      "1eae5d2d6d6a4b6ba5b306416200204c",
      "566fb763193d49ebba35b0176b26d73f",
      "71bc28a47b5d4d2788b1be4ddf5ebc34",
      "4987d18042e044fe9496d13a4b7a32c8",
      "a499e77a957c41fb841c6fd5402bf69a",
      "6d614f68f4044537b42ded6f2ab7ae45",
      "edfa31c6230d4a0c8873e97f14853176",
      "7fe09349fea543588c1785b239ae6502",
      "758e46b3fa944b5dba6fdc641dc32a42",
      "a310d8f9cafe46318d979caf8ec38902",
      "178898cfaab1424eb5242a26e0afce04",
      "9c911b5441124a36ba34ae091d1d71d6",
      "f9883a9805aa4381ab58dc1efdc89f1c",
      "5dfdeac05087475bade8bacd9d3c6596",
      "734ff4facbe54ff7baea0272c24375d3",
      "ce63759e6ac741b98f5a37e71acbaf6e"
     ]
    },
    "id": "1MbxGLxz59hf",
    "outputId": "910974e5-7ee8-4276-caa8-d1447b40258e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a41f67ce33e4b2485d3aa3f244dea35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install -q huggingface_hub\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202,
     "referenced_widgets": [
      "c5e046a8757b4b20bed7dbfdaf20935c",
      "edf669f511354f1ab83fdc9ae4798a3b",
      "d5ee83681120475098c36e03ea0ffd39",
      "b0d88d55ee244f38a5632cf30f4398ef",
      "9006536f1bfe4809bae84ffde7020955",
      "cdb5905c07c84112947126c496ab08f8",
      "8ad24293c88d4b32885aeed22a3497e2",
      "2907e3f57b724698a2c0bdf8c1ed61b7",
      "1aa8152c78294f1bbe76a2357cb26215",
      "e54a2bcef5e54c088da5b55aad011dfe",
      "e68b30e522644db18b947bbe2b73c3a3",
      "f70d63676ccb4fe99699938e2e56c468",
      "4178622bbd874501916a04ad52051240",
      "345e7dafc2a64bcd879d82fc7bc90b73",
      "2c1483c24e7f4d299c949101287a880a",
      "7ecce4366f9945f384c87d9e6df2d880",
      "1e7d8a333dcf4a3597fec900c247ff78",
      "00cad582fdd2462a99506f2ce8ec077e",
      "63072977794d4d00b5d896cf0a5b7d14",
      "46a04114dc464b16b01ecd736fece733",
      "95b5dafa866245318e73605a300d951d",
      "742d22324c444965935736ffc146e477",
      "1e6b05793d6a4e30af4f181cea366da2",
      "eb10daa786d3439cba18fae39588b3c2",
      "5402361b02454de3ab4f17f8ac752e6d",
      "cf2dbd735aee474a8e0aa5378227b800",
      "40f429b0e49b4950900dc76dc204805b",
      "5bf3709a6b3e47288eab49134438ccec",
      "71574afdb7724444b0ad2d65c7d292a1",
      "d305de7069764e5b8703b79102d18c06",
      "720032904b9e4a9397c5d11a1eec95c7",
      "b7f375a807a3457aaa1d8ce2e071146b",
      "748159b86fd24d22b0c8e38fdaacb32a"
     ]
    },
    "id": "ZC0LaIee9TQZ",
    "outputId": "478b7b02-e075-4ca4-e2be-2def72f35646"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5e046a8757b4b20bed7dbfdaf20935c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f70d63676ccb4fe99699938e2e56c468",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training_args.bin:   0%|          | 0.00/5.30k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e6b05793d6a4e30af4f181cea366da2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/498M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/VIOLET21/sentiment-bert-tweetx/commit/b7dab45d1031ebfa6e2cc887fdbac9a82a0d1e2a', commit_message='Upload folder using huggingface_hub', commit_description='', oid='b7dab45d1031ebfa6e2cc887fdbac9a82a0d1e2a', pr_url=None, repo_url=RepoUrl('https://huggingface.co/VIOLET21/sentiment-bert-tweetx', endpoint='https://huggingface.co', repo_type='model', repo_id='VIOLET21/sentiment-bert-tweetx'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import create_repo, upload_folder\n",
    "\n",
    "# Optional: create repo (auto-skip if it already exists)\n",
    "repo_name = \"sentiment-bert-tweetx\"  # Change as needed\n",
    "create_repo(repo_name, private=False)  # Set to True if private\n",
    "\n",
    "# Upload folder to the repo\n",
    "upload_folder(\n",
    "    repo_id=f\"VIOLET21/{repo_name}\",  # Replace with your username\n",
    "    folder_path=\"sentiment-bert\",          # Your model folder\n",
    "    path_in_repo=\".\",                      # Upload everything in root\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 138,
     "referenced_widgets": [
      "204a47b6ee4a440a8ddabd5ac6933043",
      "2cf04023d9f145bdb798a0e4d5454e5c",
      "0b6ba96e2a174b659bb5d4013d5cb556",
      "6e9c85a0073545a989e39aaf524dc0ed",
      "fbe503f56a084e6a9ce0dd23ff2e2dd9",
      "853b7dd165c645fa931a5d301f3e01a2",
      "46bde573ff454c049940fff98dd7da6f",
      "717fc8fa03914589a99eac286f15c2d0",
      "c57de43e665745c69002b5aa16af49f6",
      "b78c7273a2eb458c8dff8315a6f0a793",
      "8f34851c33144c4f8e48639a762a7f05"
     ]
    },
    "id": "rQFd4Dm9-mia",
    "outputId": "273560ef-43a1-485e-8f76-3cd0485d40f5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "204a47b6ee4a440a8ddabd5ac6933043",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/5.61k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/VIOLET21/sentiment-bert-tweetx/commit/2d0854616481f8ba47aa2f04b178a00b462c418f', commit_message='Upload tokenizer', commit_description='', oid='2d0854616481f8ba47aa2f04b178a00b462c418f', pr_url=None, repo_url=RepoUrl('https://huggingface.co/VIOLET21/sentiment-bert-tweetx', endpoint='https://huggingface.co', repo_type='model', repo_id='VIOLET21/sentiment-bert-tweetx'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub(\"sentiment-bert-tweetx\")\n",
    "tokenizer.push_to_hub(\"sentiment-bert-tweetx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 117,
     "referenced_widgets": [
      "b8fb32de18344b65842e0e49c3799a09",
      "d09751688a3b46f7b6d7af58f42bf31e",
      "40a237591be84a1d9041529d57b77a17",
      "567c4cb63e6e4f02b1759fd2cc5953d0",
      "d21d96b177384eeab607836e204ccd4a",
      "4093b8cbf88a42c1bef415af13faaaa3",
      "58acd7eca1594d838a982b23a21b9377",
      "413bc60ada454216b92f9e1317f0dfc3",
      "420d94c4e14b4b6f8ffada9bdf989039",
      "33584c3eb9de44efbdf3e459e37f3080",
      "cde4ab1faa184f6eb16282d100f3f67d",
      "43881544fd1347e99c8060b5b25637b3",
      "95afe1e91bda4272b66e3492ad5046bb",
      "80cf4e6ed8324995b00d646e2ef7c4e4",
      "2104f4d469e344d1b01debfc5dfb584f",
      "5323eaad0a864dd78a0fe6e4f5e26db3",
      "6ba2444900bf48f5bbdd214d0878a318",
      "0fdd48397b2c43da923f18c6dddd406c",
      "273789a818e2424a8fc678b2cb33ed7a",
      "b1529daa288c45e0ac6945db8d909c96",
      "2a1d294cfaa74696a0baa30759b25db0",
      "45360dfab38946ca91360839e5cc7a32"
     ]
    },
    "id": "HXRrRyuPAODz",
    "outputId": "86e841cc-18b1-4dd6-9f7e-46de2f1cba1e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8fb32de18344b65842e0e49c3799a09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.08k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43881544fd1347e99c8060b5b25637b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/709k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'Positive', 'score': 0.9833196997642517}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "model = pipeline(\"text-classification\", model=\"VIOLET21/sentiment-bert-tweetx\")\n",
    "result = model(\"Saya sangat senang hari ini!\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uicgI6YUg6sT",
    "outputId": "7c1c1691-6172-4836-e59b-705dbf2c80a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text: Saya sangat senang hari ini!\n",
      "Model output: [[{'label': 'Positive', 'score': 0.9833196997642517}, {'label': 'Neutral', 'score': 0.013673769310116768}, {'label': 'Negative', 'score': 0.003006430808454752}]]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "# Set your Hugging Face token\n",
    "# It's better to use environment variables for sensitive data\n",
    "HF_TOKEN = \"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\"  # Replace with your actual token\n",
    "\n",
    "# Define the API URL for your model\n",
    "API_URL = \"https://api-inference.huggingface.co/models/VIOLET21/sentiment-bert-tweet\"\n",
    "\n",
    "# Set up headers with your token\n",
    "headers = {\"Authorization\": f\"Bearer {HF_TOKEN}\"}\n",
    "\n",
    "# Function to query the model\n",
    "def query(payload):\n",
    "    response = requests.post(API_URL, headers=headers, json=payload)\n",
    "    return response.json()\n",
    "\n",
    "# Test with an Indonesian sentence\n",
    "test_text = \"Saya sangat senang hari ini!\"\n",
    "output = query({\"inputs\": test_text})\n",
    "\n",
    "print(f\"Input text: {test_text}\")\n",
    "print(f\"Model output: {output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zSJDdLGlxMmN",
    "outputId": "bcd17581-c7fa-4f7c-ad16-91dac728a83d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'label': 'Positive', 'score': 0.9833196997642517}, {'label': 'Neutral', 'score': 0.013673769310116768}, {'label': 'Negative', 'score': 0.003006430808454752}]]\n"
     ]
    }
   ],
   "source": [
    "# Using the Inference API\n",
    "import requests\n",
    "API_URL = \"https://api-inference.huggingface.co/models/VIOLET21/sentiment-bert-tweet\"\n",
    "headers = {\"Authorization\": \"Bearer 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\"}\n",
    "def query(payload):\n",
    "    response = requests.post(API_URL, headers=headers, json=payload)\n",
    "    return response.json()\n",
    "output = query({\"inputs\": \"Saya sangat senang hari ini!\"})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x7wgUAqC0zut"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
